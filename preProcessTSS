#!/usr/bin/env python
# -*- encoding: utf-8 -*-
"""
@File    :   new_feature.py
@Contact :   zhumeng@bupt.edu.cn
@License :   (C)Copyright 2019 zhumeng
@Modify Time      @Author    @Version    @Desciption
------------      -------    --------    -----------
2019/12/9 20:57      xm         1.0          None
"""
import time
import numpy as np
import pandas as pd
import os
from collections import Counter

'''
DEFINITION: 
PacketToProxy: 1
PacketFromProxy: -1
'''
rootPath = os.path.abspath(os.path.dirname(__file__)).split('application')[0]  # /home/byr/xiaomeng/
proxy_port = tuple(('7a', '31'))

app_label = {
    'Chrome': "0",
    # 'Bilibili': "1",
    # 'WeChat': "2",
    # 'QQMusic': "3",
    # 'SSH': "4",
    # 'IQIYI': "4",
    # 'YouKu': "5",
}


def read_from_txt(fillna=True):
    """
    Function: read raw data from txt.file of each Application which obtained from Wireshark and filter unnecessary record
    :param fillna: whether or not fill the packet NULL with 0
    :return: a Dict contain all DataFrame of each Application. s.t. data={'app1':app1_df, ...}
    """
    # DataFrame Initialization
    data = {}
    for k, v in app_label.items():
        df1 = pd.read_csv(str(rootPath) + "dataset/raw_data_simple/" + k + ".txt", sep="\n", header=None,
                          engine='python',
                          skiprows=lambda x: x % 4 != 2, dtype='str')  # read from csv data
        df1 = df1[0].str.split('  ', expand=True)
        df1 = df1[1].str.split('|', expand=True).drop([0], axis=1)
        if fillna:
            df1.replace(to_replace=r'^\s*$', value=np.nan, regex=True, inplace=True)  # fill 0 into packet
            df1 = df1.fillna('0')
        data[k] = df1
        print(df1.shape[0])
    return data


def packet_list(dict1, dict2):
    for k, v in dict1.items():
        if dict2.__contains__(k):
            dict1[k] = np.sort(np.unique(np.concatenate((dict1[k], dict2[k]), axis=0)))
    return dict1


def session_merge(data):
    """
    Function: merge the packets which belong to same session
    :param data: a Dict contain all DataFrame of each Application. s.t. data={'app1':app1_df, ...}
    :return: lists[Chrome] = {port1:[1,2,10,33,....], port2:[3,4,5,6,....],...}
    """
    lists = {}
    for aName, df in data.items():
        grouped_by_src = df.groupby([35, 36])  # return GroupBy Object
        grouped_by_dst = df.groupby([37, 38])
        list_by_src = grouped_by_src.indices
        list_by_dst = grouped_by_dst.indices
        lists[aName] = packet_list(list_by_src, list_by_dst)
        # print(aName + ' ... [Done]')
    return lists


def rawdata_format(data, lists, sess_size=10, pck_str=16, pck_len=160):
    """
    Function: transform raw data into intended format(1 row = 1 session with 10 packets and 160bytes/packet)
    :param data: a Dict contain all DataFrame of each Application. s.t. data={'app1':app1_df, ...}
    :param lists: lists[Chrome] = {port1:[1,2,10,33,....], port2:[3,4,5,6,....],...}
    :param sess_size: number of packet selected from one session
    :param pck_str: packet start position
    :param pck_len: packet length(fixed)
    :return: sorted packets in session in hex
    """
    # slice 16th~175th, column index keep same
    ndata = {}
    for aName, df in data.items():
        df = df.iloc[:, pck_str:pck_str + pck_len]
        df.replace(to_replace=r'^\s*$', value=np.nan, regex=True, inplace=True)  # fill 0 into packet
        df = df.fillna('0')
        sessions = pd.DataFrame()
        for port, l in lists.get(aName).items():
            if port == proxy_port:
                continue
            else:
                s = pd.concat([df.iloc[i] for i in l[0:sess_size]], axis=0, ignore_index=True)
                sessions = pd.concat([sessions, s], axis=1, ignore_index=True)
        # data[aName] = label_data(aName, sessions.T, sess_size, pck_len)
        sessions = sessions.T
        sessions.replace(to_replace=r'^\s*$', value=np.nan, regex=True, inplace=True)  # fill 0 into session
        # print(sessions.shape)
        ndata[aName] = sessions.fillna('0')

        # print(aName + ' ... [Done]')
    return ndata


def hex_convert_dec(data):
    """
        Function:  convert hex into dec
        :param data: a Dict contain all df of each Application data={'app1':app1_df, ...}
        """
    for fname, df1 in data.items():
        hex_list = df1.to_numpy()
        dec_list = [[int(hex_list[i][j], 16) for j in range(len(hex_list[i]))] for i in range(len(hex_list))]
        data[fname] = pd.DataFrame(dec_list)
        print(fname, df1.shape[0])
    return data


def time_img(data, lists, sess_size=10):
    """
    Function: packet length(16)+TCP window size(16)+direction(2)+interval-time(6)
    :param data: a Dict contain all DataFrame of each Application. s.t. data={'app1':app1_df, ...}
    :param k: top k byte values appears in the session
    :return: data: data[Chrome] = dataframe[[0,1,2,...,39]] 10*40
    """
    ndata = {}
    for aName, df in data.items():
        ss = np.array([np.arange(0, 400)])
        for port, l in lists.get(aName).items():
            if port == proxy_port:
                continue
            else:
                s = []
                previous = l[0]
                for i in l[0:min(sess_size, len(l))]:
                    # '0100010000011101'
                    pcklen = '{:0>16b}'.format(int("".join(df.iloc[i, 16:18].to_numpy()), 16) - 40) if df.at[i, 24] == '06' \
                        else '{:0>16b}'.format(int("".join(df.iloc[i, 16:18].to_numpy()), 16) - 28)
                    # '0100010000011101'
                    tcplen = '{:0>16b}'.format(int("".join(df.iloc[i, 48:50].to_numpy()), 16)) if df.at[i, 24] == '06' \
                        else '{:0>16b}'.format(0)
                    dirct = '0' if tuple(df.iloc[i, 34:36].values) == proxy_port else '1'
                    intime = '{:0>7b}'.format(i - previous) if i - previous < 128 else '{0:0>7b}'.format(127)
                    previous = i
                    s.extend(num2arr(pcklen + tcplen + dirct + intime))
                if len(s) != 400:
                    s = s + [0] * (400 - len(s))
                ss = np.concatenate((ss, np.array([s])), axis=0)
        # print(ss.shape)
        ndata[aName] = pd.DataFrame(ss[1:], columns=ss[0])
        # print(aName + ' ... [Done]')
    return ndata


def num2arr(data):
    str_data = []
    for x in data:
        str_data.append(x)
    return str_data


def spatial_img(data, lists, k=41): # 排除0和00
    """
    Function: count the byte distribution at top 40
    :param data: a Dict contain all DataFrame of each Application. s.t. data={'app1':app1_df, ...}
    :param k: top k byte values appears in the session
    :return: data: data[Chrome] = dataframe[[233,10,7,...,19]] 10*40
    """
    ndata = {}
    for aName, df in data.items():
        top_ss = np.array([np.arange(0, 400)])
        for port, l in lists.get(aName).items():
            if port == proxy_port:
                continue
            else:
                top_ks = []
                for i in l[0:min(10, len(l))]:
                    top_k = Counter(df.iloc[i].tolist()).most_common(k)
                    tmp = [int(rst[0], 16) for rst in top_k[1:]]
                    if len(tmp) != 40:
                        tmp = tmp + [0] * (40 - len(tmp))
                    top_ks.extend(tmp)
                if len(top_ks) != 400:
                    top_ks = top_ks + [0] * (400 - len(top_ks))
                top_ss = np.concatenate((top_ss, np.array([top_ks])), axis=0)
        # print(top_ss.shape)
        ndata[aName] = pd.DataFrame(top_ss[1:], columns=top_ss[0])
        # print(aName + ' ... [Done]')
    return ndata


def write_into_csv(time, sptl, data):
    """
    Function:write the sessions bytes of each Application into csv.file
    :param data: a Dict contain all df of each Application data={'app1':app1_df, ...}
    """
    for name, d, s, b in zip(data.keys(), time.values(), sptl.values(), data.values()):
        result = pd.concat([d, s, b], axis=1, ignore_index=True)
        result[result.shape[1]] = app_label[name]
        result.to_csv(str(rootPath) + "dataset/labeled_data_TSS/" + name + ".csv", mode='a', header=None, index=False)
        print(name + ' ... [Done]')


if __name__ == "__main__":
    pd.set_option('mode.chained_assignment', None)
    start = time.time()
    # print("--------------------START--------------------")
    # print("1. Read from txt:")
    pData = read_from_txt()
    # print('---------------------------------------------')
    # print("2. Merge session:")
    pList = session_merge(pData)
    # print('---------------------------------------------')
    # print("3. Format session:")
    sData = rawdata_format(pData, pList)
    # print('---------------------------------------------')
    # print("4. Decimal  conversion:")
    dData = hex_convert_dec(sData)
    print('--------------------------Temporal Feature--------------------------')
    # print("5. Add extra feature:")
    print("Processing...")
    timeData = time_img(pData, pList)
    print("DONE!")
    print('--------------------------Statistics Feature--------------------------')
    print("Processing...")
    sptlData = spatial_img(pData, pList)
    print("DONE!")
    print('--------------------------Write into csv--------------------------')

    # timeData=(0,399) + sptlData=(400,799) + dData=(800,2400) + label(2401)
    # write_into_csv(timeData, sptlData, dData)
    print("\nPreprocessed finished cost time:%f" % (time.time() - start))
